{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eefa1e15-9ef9-4a53-ba8c-d9a51eae4984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73947701-7091-4dba-a056-9bb7df469000",
   "metadata": {},
   "source": [
    "## 0. í•™ìŠµ ì¤€ë¹„\n",
    "- ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "- í™˜ê²½ ì„¤ì • (íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ë¡œë“œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8d9f476-c678-40ec-8cae-acbe64b96a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í™˜ê²½ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# === ì…ì¶œë ¥ ê²½ë¡œ ===\n",
    "os.environ.setdefault(\"CSV_PATH\", \"labeled_sentences_voted_every_data.csv\")   # seed íŒŒì¼ ê²½ë¡œ\n",
    "\n",
    "# ë°°ì¹˜ ë‹¨ìœ„ (í•œ ë²ˆì— ëª‡ ê°œì˜ í•­ëª©ì„ ìƒì„±ì‹œí‚¬ì§€)\n",
    "os.environ.setdefault(\"BATCH_SIZE\", \"10\")\n",
    "\n",
    "# ìƒì„± ë‹¤ì–‘ì„±\n",
    "os.environ.setdefault(\"TEMPERATURE\", \"0.8\")\n",
    "os.environ.setdefault(\"TOP_P\", \"0.9\")\n",
    "\n",
    "print(\"í™˜ê²½ì„¤ì • ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b24d0037-3b6f-4829-baa3-69876f9cfc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shape: (50000, 5)\n",
      "Loaded shape: (1260, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label_pred</th>\n",
       "      <th>agree_rate</th>\n",
       "      <th>certainty_avg</th>\n",
       "      <th>accept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì „í™”ë°›ì•˜ìŠµë‹ˆë‹¤ #@ì†Œì†#ì…ë‹ˆë‹¤</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ê·¸ê²ƒë„ í•´ì£¼ì‹œê³  ë‹¤ í•´ì£¼ì„¸ìš” ì™œëƒë©´ ì €ë„ ì´ì œ ëª‡ ë²ˆì„ ì°¸ì€ ê±°ë¼ì„œìš”</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ë„¤ ë‹¤ë¥¸ ê±´ì˜ì‚¬í•­ ìˆìœ¼ì‹­ë‹ˆê¹Œ</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì•„ ê·¸ë˜ìš” #@ê¸°íƒ€#ë¬¸ê³ ë‚˜ #@ê¸°íƒ€#ë¬¸ê³ ì—ë„ ì—†ì–´ìš”</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ê°ì‚¬í•©ë‹ˆë‹¤ ê³ ê°ë‹˜ #@ì†Œì†# ê³ ê°ì„¼í„°ì˜€ìŠµë‹ˆë‹¤</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sentence  label_pred  agree_rate  \\\n",
       "0                        ì „í™”ë°›ì•˜ìŠµë‹ˆë‹¤ #@ì†Œì†#ì…ë‹ˆë‹¤           0         1.0   \n",
       "1  ê·¸ê²ƒë„ í•´ì£¼ì‹œê³  ë‹¤ í•´ì£¼ì„¸ìš” ì™œëƒë©´ ì €ë„ ì´ì œ ëª‡ ë²ˆì„ ì°¸ì€ ê±°ë¼ì„œìš”           0         1.0   \n",
       "2                         ë„¤ ë‹¤ë¥¸ ê±´ì˜ì‚¬í•­ ìˆìœ¼ì‹­ë‹ˆê¹Œ           0         1.0   \n",
       "3            ì•„ ê·¸ë˜ìš” #@ê¸°íƒ€#ë¬¸ê³ ë‚˜ #@ê¸°íƒ€#ë¬¸ê³ ì—ë„ ì—†ì–´ìš”           0         1.0   \n",
       "4                ê°ì‚¬í•©ë‹ˆë‹¤ ê³ ê°ë‹˜ #@ì†Œì†# ê³ ê°ì„¼í„°ì˜€ìŠµë‹ˆë‹¤           0         1.0   \n",
       "\n",
       "   certainty_avg  accept  \n",
       "0             83    True  \n",
       "1             75    True  \n",
       "2             85    True  \n",
       "3             76    True  \n",
       "4            100    True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>domain</th>\n",
       "      <th>task</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>source</th>\n",
       "      <th>seed_id</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì˜¤ëŠ˜ ë°¤ì— ìƒ‰ê° ì²´í¬ ê°€ëŠ¥í•˜ì‹ ê°€ìš”?</td>\n",
       "      <td>design_production</td>\n",
       "      <td>CREATE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>teacher</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ê¸ˆìš”ì¼ ì˜¤í›„ í‚¥ì˜¤í”„ ë¯¸íŒ… í• ê¹Œìš”?</td>\n",
       "      <td>design_production</td>\n",
       "      <td>CREATE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>teacher</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ì±„ìƒ‰ ì¼ì • ì´ë²ˆ ì£¼ë¡œ ë‹¹ê¸¸ ìˆ˜ ìˆì„ê¹Œìš”?</td>\n",
       "      <td>design_production</td>\n",
       "      <td>UPDATE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>teacher</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ì‰í‚¹ ë¦¬ë·° ë‚´ì¼ ì˜¤ì „ì´ë©´ ê´œì°®ìœ¼ì‹¤ê¹Œìš”?</td>\n",
       "      <td>design_production</td>\n",
       "      <td>CREATE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>teacher</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ì˜¤ëŠ˜ íšŒì˜ ê·¸ëƒ¥ íŒ¨ìŠ¤í•˜ì£ </td>\n",
       "      <td>design_production</td>\n",
       "      <td>CANCEL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>teacher</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sentence             domain    task  label  confidence  \\\n",
       "1     ì˜¤ëŠ˜ ë°¤ì— ìƒ‰ê° ì²´í¬ ê°€ëŠ¥í•˜ì‹ ê°€ìš”?  design_production  CREATE      1        0.92   \n",
       "3      ê¸ˆìš”ì¼ ì˜¤í›„ í‚¥ì˜¤í”„ ë¯¸íŒ… í• ê¹Œìš”?  design_production  CREATE      1        0.95   \n",
       "5  ì±„ìƒ‰ ì¼ì • ì´ë²ˆ ì£¼ë¡œ ë‹¹ê¸¸ ìˆ˜ ìˆì„ê¹Œìš”?  design_production  UPDATE      1        0.89   \n",
       "7   ì‰í‚¹ ë¦¬ë·° ë‚´ì¼ ì˜¤ì „ì´ë©´ ê´œì°®ìœ¼ì‹¤ê¹Œìš”?  design_production  CREATE      1        0.91   \n",
       "8           ì˜¤ëŠ˜ íšŒì˜ ê·¸ëƒ¥ íŒ¨ìŠ¤í•˜ì£   design_production  CANCEL      1        0.94   \n",
       "\n",
       "    source  seed_id  epoch  \n",
       "1  teacher      1.0      0  \n",
       "3  teacher      3.0      0  \n",
       "5  teacher      5.0      0  \n",
       "7  teacher      7.0      0  \n",
       "8  teacher      8.0      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# í™˜ê²½ ì„¤ì •ê³¼ ë°ì´í„° ë¡œë“œ\n",
    "import re, random, json, types\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "CSV_PATH = os.getenv(\"CSV_PATH\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df_daily = pd.read_csv(CSV_PATH)\n",
    "df_biz = pd.read_csv(\"schedule_dataset_augmented_epoch_2.csv\")\n",
    "df_daily = df_daily.drop(columns=[\"file_path\"])\n",
    "df_biz = df_biz[df_biz[\"label\"] != 0]\n",
    "print(\"Loaded shape:\", df_daily.shape)\n",
    "print(\"Loaded shape:\", df_biz.shape)\n",
    "display(df_daily.head())\n",
    "display(df_biz.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3ab08fd4-d2f4-48fd-b66e-d24497f9f18f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using columns -> text: sentence label: label_pred\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40000, 10000)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "# í…ìŠ¤íŠ¸/ë¼ë²¨ ì»¬ëŸ¼ ìë™ ê°ì§€ ë° ë¶„í• \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_col = \"sentence\" if \"sentence\" in df.columns else df.columns[0]\n",
    "label_col = \"label_pred\" if \"label_pred\" in df.columns else df.columns[-1]\n",
    "print(\"Using columns -> text:\", text_col, \"label:\", label_col)\n",
    "\n",
    "df = df[[text_col, label_col]].dropna().reset_index(drop=True)\n",
    "X = df[text_col].astype(str).values\n",
    "y = df[label_col].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=38, stratify=y\n",
    ")\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33139942-d8a1-4950-9287-da4645eb4dcb",
   "metadata": {},
   "source": [
    "## TF-IDF ë¶„ë¥˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81930558-7b31-41c4-aa0c-e17d654238a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFâ€‘IDF char Accuracy: 0.9701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      9417\n",
      "           1       0.74      0.75      0.75       583\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.86      0.87      0.86     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n",
      "TFâ€‘IDF word Accuracy: 0.9279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      9417\n",
      "           1       0.43      0.68      0.52       583\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.70      0.81      0.74     10000\n",
      "weighted avg       0.95      0.93      0.94     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1) char ngram ê¸°ë°˜\n",
    "tfidf_char = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(analyzer=\"char\", ngram_range=(2,5), min_df=3)),\n",
    "    (\"clf\", LinearSVC(class_weight=\"balanced\"))\n",
    "])\n",
    "tfidf_char.fit(X_train, y_train)\n",
    "pred_char = tfidf_char.predict(X_test)\n",
    "acc_char = accuracy_score(y_test, pred_char)\n",
    "print(\"TFâ€‘IDF char Accuracy:\", acc_char)\n",
    "print(classification_report(y_test, pred_char))\n",
    "\n",
    "# 2) word ê¸°ë°˜\n",
    "tfidf_word = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(analyzer=\"word\", token_pattern=r\"(?u)\\b\\w+\\b\", min_df=3)),\n",
    "    (\"clf\", LinearSVC(class_weight=\"balanced\"))\n",
    "])\n",
    "tfidf_word.fit(X_train, y_train)\n",
    "pred_word = tfidf_word.predict(X_test)\n",
    "acc_word = accuracy_score(y_test, pred_word)\n",
    "print(\"TFâ€‘IDF word Accuracy:\", acc_word)\n",
    "print(classification_report(y_test, pred_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "538bb1c0-db7a-402b-a8df-993ad5b8b626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>domain</th>\n",
       "      <th>task</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>source</th>\n",
       "      <th>seed_id</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë°°ê²½ ëŸ¬í”„ ìˆ˜ì •ë³¸ ì—¬ê¸° ìˆì–´ìš”</td>\n",
       "      <td>design_production</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>teacher</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì˜¤ëŠ˜ ë°¤ì— ìƒ‰ê° ì²´í¬ ê°€ëŠ¥í•˜ì‹ ê°€ìš”?</td>\n",
       "      <td>design_production</td>\n",
       "      <td>CREATE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>teacher</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì‹±í¬í‘œ ë‹¤ì‹œ ì˜¬ë ¤ë“œë¦´ê²Œìš”</td>\n",
       "      <td>design_production</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>teacher</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ê¸ˆìš”ì¼ ì˜¤í›„ í‚¥ì˜¤í”„ ë¯¸íŒ… í• ê¹Œìš”?</td>\n",
       "      <td>design_production</td>\n",
       "      <td>CREATE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>teacher</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì˜¤ëŠ˜ ì½˜í‹° í”¼ë“œë°±ë§Œ ì£¼ì„¸ìš”</td>\n",
       "      <td>design_production</td>\n",
       "      <td>NONE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>teacher</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sentence             domain    task  label  confidence   source  \\\n",
       "0     ë°°ê²½ ëŸ¬í”„ ìˆ˜ì •ë³¸ ì—¬ê¸° ìˆì–´ìš”  design_production    NONE      0        0.99  teacher   \n",
       "1  ì˜¤ëŠ˜ ë°¤ì— ìƒ‰ê° ì²´í¬ ê°€ëŠ¥í•˜ì‹ ê°€ìš”?  design_production  CREATE      1        0.92  teacher   \n",
       "2        ì‹±í¬í‘œ ë‹¤ì‹œ ì˜¬ë ¤ë“œë¦´ê²Œìš”  design_production    NONE      0        0.98  teacher   \n",
       "3   ê¸ˆìš”ì¼ ì˜¤í›„ í‚¥ì˜¤í”„ ë¯¸íŒ… í• ê¹Œìš”?  design_production  CREATE      1        0.95  teacher   \n",
       "4       ì˜¤ëŠ˜ ì½˜í‹° í”¼ë“œë°±ë§Œ ì£¼ì„¸ìš”  design_production    NONE      0        0.97  teacher   \n",
       "\n",
       "   seed_id  epoch  \n",
       "0      0.0      0  \n",
       "1      1.0      0  \n",
       "2      2.0      0  \n",
       "3      3.0      0  \n",
       "4      4.0      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_labeled = pd.read_csv(\"schedule_dataset_augmented_epoch_2.csv\")\n",
    "display(df_labeled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "765c5fb6-8790-475f-94ba-039b45724cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 ë°°ê²½ ëŸ¬í”„ ìˆ˜ì •ë³¸ ì—¬ê¸° ìˆì–´ìš”\n",
       "1                              ì˜¤ëŠ˜ ë°¤ì— ìƒ‰ê° ì²´í¬ ê°€ëŠ¥í•˜ì‹ ê°€ìš”?\n",
       "2                                    ì‹±í¬í‘œ ë‹¤ì‹œ ì˜¬ë ¤ë“œë¦´ê²Œìš”\n",
       "3                               ê¸ˆìš”ì¼ ì˜¤í›„ í‚¥ì˜¤í”„ ë¯¸íŒ… í• ê¹Œìš”?\n",
       "4                                   ì˜¤ëŠ˜ ì½˜í‹° í”¼ë“œë°±ë§Œ ì£¼ì„¸ìš”\n",
       "                           ...                    \n",
       "1995              ì˜¤ëŠ˜ 1ì‹œ ì±„ìƒ‰íŒ€ ì‹œê°„ ë§ì•„? í˜¹ì‹œ 15ë¶„ ëŠ¦ì¶°ë„ ê´œì°®ì•„?\n",
       "1996    ë‚´ì¼ ë°”ë¹ ì„œ ì±„ìƒ‰ ì„¸ì…˜ ëª» í•˜ê² ì–´... ë­ í• ê¹Œ? í˜¹ì‹œ ë‹¤ë¥¸ ì‹œê°„ì´ ìˆë‚˜ìš”?\n",
       "1997                      ì½˜í‹° ì´ˆì•ˆ ì¢€ ë” ë¹¨ë¦¬ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”? ğŸ™ƒ\n",
       "1998      ê¸ˆìš”ì¼ ë¦¬ë·° ì‹œê°„, 15ë¶„ ëŠ¦ì¶°ë„ ê´œì°®ì•„? ë‚´ì¼ ì•„ì¹¨ì— ë‹¤ì‹œ ì¡°ìœ¨í•´ë³¼ê²Œ.\n",
       "1999                           ì˜¤ëŠ˜ ì½˜í‹° í”¼ë“œë°± ì¢€ ì£¼ì‹¤ë˜ìš”? ğŸ‘€\n",
       "Name: sentence, Length: 2000, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "1995    1\n",
       "1996    1\n",
       "1997    0\n",
       "1998    1\n",
       "1999    0\n",
       "Name: label, Length: 2000, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TF-IDF (char) ê²°ê³¼ ===\n",
      "Accuracy: 0.807\n",
      "Confusion Matrix:\n",
      " [[ 550  190]\n",
      " [ 196 1064]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.737     0.743     0.740       740\n",
      "           1      0.848     0.844     0.846      1260\n",
      "\n",
      "    accuracy                          0.807      2000\n",
      "   macro avg      0.793     0.794     0.793      2000\n",
      "weighted avg      0.807     0.807     0.807      2000\n",
      "\n",
      "\n",
      "=== TF-IDF (word) ê²°ê³¼ ===\n",
      "Accuracy: 0.7805\n",
      "Confusion Matrix:\n",
      " [[ 502  238]\n",
      " [ 201 1059]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.714     0.678     0.696       740\n",
      "           1      0.816     0.840     0.828      1260\n",
      "\n",
      "    accuracy                          0.780      2000\n",
      "   macro avg      0.765     0.759     0.762      2000\n",
      "weighted avg      0.779     0.780     0.779      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# X, y ì„¤ì •\n",
    "X_test = df_labeled[\"sentence\"]\n",
    "y_test = df_labeled[\"label\"]   # teacher ëª¨ë¸ë¡œ ë¼ë²¨ë§ëœ ê²°ê³¼\n",
    "display(X_test)\n",
    "display(y_test.count())\n",
    "\n",
    "# --- TF-IDF char ëª¨ë¸ ---\n",
    "pred_char = tfidf_char.predict(X_test)\n",
    "acc_char = accuracy_score(y_test, pred_char)\n",
    "print(\"\\n=== TF-IDF (char) ê²°ê³¼ ===\")\n",
    "print(\"Accuracy:\", acc_char)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, pred_char))\n",
    "print(classification_report(y_test, pred_char, digits=3))\n",
    "\n",
    "# --- TF-IDF word ëª¨ë¸ ---\n",
    "pred_word = tfidf_word.predict(X_test)\n",
    "acc_word = accuracy_score(y_test, pred_word)\n",
    "print(\"\\n=== TF-IDF (word) ê²°ê³¼ ===\")\n",
    "print(\"Accuracy:\", acc_word)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, pred_word))\n",
    "print(classification_report(y_test, pred_word, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d19b2eaf-37da-4dbd-ab0b-35513de73fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TF-IDF char] thr=1.4743 (Pâ‰¥0.95) | VAL-like P=0.950, R=0.317\n",
      "TEST-ish  P=0.950 R=0.317 F1=0.475 PR-AUC=0.912\n",
      "[TF-IDF word] thr=2.3566 (Pâ‰¥0.95) | VAL-like P=0.950, R=0.167\n",
      "TEST-ish  P=0.950 R=0.167 F1=0.284 PR-AUC=0.873\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, average_precision_score\n",
    "\n",
    "def pick_thr_for_precision(y_true, scores, target_p=0.90):\n",
    "    p, r, th = precision_recall_curve(y_true, scores)\n",
    "    cands = [(pp, rr, tt) for pp, rr, tt in zip(p[:-1], r[:-1], th) if pp >= target_p]\n",
    "    if cands:\n",
    "        # precision ë§Œì¡± ì¤‘ recall ìµœëŒ€\n",
    "        best = max(cands, key=lambda x: x[1])\n",
    "        return best[2], {\"P\": best[0], \"R\": best[1], \"picked\": f\"Pâ‰¥{target_p}\"}\n",
    "    # ì—†ìœ¼ë©´ F1 ìµœëŒ€ ì§€ì \n",
    "    f1s = []\n",
    "    for pp, rr, tt in zip(p[:-1], r[:-1], th):\n",
    "        f1 = 0 if (pp+rr)==0 else 2*pp*rr/(pp+rr)\n",
    "        f1s.append((f1, tt, pp, rr))\n",
    "    f1s.sort(reverse=True, key=lambda x: x[0])\n",
    "    f1, thr, pp, rr = f1s[0]\n",
    "    return thr, {\"P\": pp, \"R\": rr, \"F1\": f1, \"picked\": \"maxF1\"}\n",
    "\n",
    "def eval_with_thr(model, X, y, target_p=0.90, name=\"model\"):\n",
    "    scores = model.decision_function(X)  # LinearSVC ì ìˆ˜\n",
    "    thr, info = pick_thr_for_precision(y, scores, target_p)\n",
    "    y_pred = (scores >= thr).astype(int)\n",
    "    P = precision_score(y, y_pred, zero_division=0)\n",
    "    R = recall_score(y, y_pred, zero_division=0)\n",
    "    F1 = f1_score(y, y_pred, zero_division=0)\n",
    "    AP = average_precision_score(y, scores)\n",
    "    print(f\"[{name}] thr={thr:.4f} ({info['picked']}) | VAL-like P={info['P']:.3f}, R={info['R']:.3f}\")\n",
    "    print(f\"TEST-ish  P={P:.3f} R={R:.3f} F1={F1:.3f} PR-AUC={AP:.3f}\")\n",
    "    return thr, (P,R,F1,AP)\n",
    "\n",
    "# df_labeled ì „ì²´ê°€ í…ŒìŠ¤íŠ¸ì…‹ì´ë¼ë©´ ê·¸ëŒ€ë¡œ ì ìš© (í˜¹ì€ ë‚´ë¶€ì—ì„œ 80/20 ìª¼ê°œ ì„ê³„ê°’ ê³ ë¥´ê³  ë™ì¼ ë¶„í¬ì— í‰ê°€)\n",
    "thr_char, _ = eval_with_thr(tfidf_char, X_test, y_test, target_p=0.95, name=\"TF-IDF char\")\n",
    "thr_word, _ = eval_with_thr(tfidf_word, X_test, y_test, target_p=0.95, name=\"TF-IDF word\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34f250a0-a27b-44a9-9d32-230a231f219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "cal_char = CalibratedClassifierCV(tfidf_char, method=\"sigmoid\", cv=3).fit(X_train, y_train)\n",
    "probs = cal_char.predict_proba(X_test)[:,1]\n",
    "# â†’ precision ëª©í‘œì— ë§ì¶° threshold ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f4f19c64-ddf2-48e9-9f28-cc2cde02f116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Threshold] Pâ‰¥0.9 -> thr=0.6493  (VAL-like P=0.900, R=0.652)\n",
      "[TEST] Precision=0.900  Recall=0.652  F1=0.756  PR-AUC=0.908\n",
      "Confusion Matrix [rows=true 0/1, cols=pred 0/1]:\n",
      " [[649  91]\n",
      " [439 821]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.597     0.877     0.710       740\n",
      "           1      0.900     0.652     0.756      1260\n",
      "\n",
      "    accuracy                          0.735      2000\n",
      "   macro avg      0.748     0.764     0.733      2000\n",
      "weighted avg      0.788     0.735     0.739      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, precision_score, recall_score, f1_score,\n",
    "    average_precision_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "def pick_thr_for_precision(y_true, probs, target_p=0.90):\n",
    "    p, r, th = precision_recall_curve(y_true, probs)\n",
    "    # thresholds ê¸¸ì´ëŠ” p,rë³´ë‹¤ 1 ì‘ìŒ\n",
    "    cands = [(pp, rr, tt) for pp, rr, tt in zip(p[:-1], r[:-1], th) if pp >= target_p]\n",
    "    if cands:\n",
    "        # precision ë§Œì¡± ì¤‘ recall ìµœëŒ€ ì§€ì \n",
    "        best = max(cands, key=lambda x: x[1])\n",
    "        return best[2], {\"picked_by\": f\"Pâ‰¥{target_p}\", \"P\": best[0], \"R\": best[1]}\n",
    "    # fallback: F1 ìµœëŒ€ ì§€ì \n",
    "    f1s = []\n",
    "    for pp, rr, tt in zip(p[:-1], r[:-1], th):\n",
    "        f1 = 0 if (pp+rr)==0 else 2*pp*rr/(pp+rr)\n",
    "        f1s.append((f1, tt, pp, rr))\n",
    "    f1s.sort(reverse=True, key=lambda x: x[0])\n",
    "    f1, thr, pp, rr = f1s[0]\n",
    "    return thr, {\"picked_by\": \"maxF1\", \"P\": pp, \"R\": rr, \"F1\": f1}\n",
    "\n",
    "# 1) ì„ê³„ê°’ ì„ íƒ (ì˜ˆ: Precision 0.90 ëª©í‘œ)\n",
    "thr, info = pick_thr_for_precision(y_test, probs, target_p=0.9)\n",
    "print(f\"[Threshold] {info['picked_by']} -> thr={thr:.4f}  (VAL-like P={info['P']:.3f}, R={info['R']:.3f})\")\n",
    "\n",
    "# 2) í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ ë° ì§€í‘œ\n",
    "y_pred = (probs >= thr).astype(int)\n",
    "\n",
    "P = precision_score(y_test, y_pred, zero_division=0)\n",
    "R = recall_score(y_test, y_pred, zero_division=0)\n",
    "F1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "AP = average_precision_score(y_test, probs)  # PR-AUCì€ í™•ë¥  ê¸°ë°˜\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "\n",
    "print(f\"[TEST] Precision={P:.3f}  Recall={R:.3f}  F1={F1:.3f}  PR-AUC={AP:.3f}\")\n",
    "print(\"Confusion Matrix [rows=true 0/1, cols=pred 0/1]:\\n\", cm)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79dcf983-959f-4693-b9b2-3a3068f20e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using columns -> text: sentence label: label_pred\n",
      "['ì „í™”ë°›ì•˜ìŠµë‹ˆë‹¤ #@ì†Œì†#ì…ë‹ˆë‹¤' 'ê·¸ê²ƒë„ í•´ì£¼ì‹œê³  ë‹¤ í•´ì£¼ì„¸ìš” ì™œëƒë©´ ì €ë„ ì´ì œ ëª‡ ë²ˆì„ ì°¸ì€ ê±°ë¼ì„œìš”'\n",
      " 'ë„¤ ë‹¤ë¥¸ ê±´ì˜ì‚¬í•­ ìˆìœ¼ì‹­ë‹ˆê¹Œ' ... 'ì˜ˆ ìš°ì„  ì„¼í„°ì—ì„œ í•˜ê²Œë˜ë©´ìš”' 'ì—´ë¦°íœì…˜ë¯¼ë°•ì´ìš” í•œë²ˆ ì°¾ì•„ë´ì•¼ê² ë„¤ìš”'\n",
      " 'ë„¤ ë§ì”€ ì£¼ì‹œë©´ ì•ˆë‚´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤'] [0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    " # í…ìŠ¤íŠ¸/ë¼ë²¨ ì»¬ëŸ¼ ìë™ ê°ì§€ ë° ë¶„í• \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_col = \"sentence\" if \"sentence\" in df.columns else df.columns[0]\n",
    "label_col = \"label\" if \"label\" in df.columns else df.columns[-1]\n",
    "print(\"Using columns -> text:\", text_col, \"label:\", label_col)\n",
    "\n",
    "df = df[[text_col, label_col]].dropna().reset_index(drop=True)\n",
    "X_test = df[text_col].astype(str).values\n",
    "Y_test = df[label_col].values\n",
    "\n",
    "print(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de95d111-6955-43e9-b101-0ddad0e38487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFâ€‘IDF char Accuracy: 0.29228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.03      0.51      0.05      1830\n",
      "        True       0.94      0.28      0.44     48170\n",
      "\n",
      "    accuracy                           0.29     50000\n",
      "   macro avg       0.48      0.40      0.24     50000\n",
      "weighted avg       0.90      0.29      0.42     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3) ê¸°ì¡´ ë°ì´í„°ì…‹ í‰ê°€\n",
    "\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "model = joblib.load(\"artifacts/char_calibrated.joblib\")\n",
    "\n",
    "pred_char = model.predict(X_test)\n",
    "acc_char = accuracy_score(Y_test, pred_char)\n",
    "print(\"TFâ€‘IDF char Accuracy:\", acc_char)\n",
    "print(classification_report(Y_test, pred_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b8018e-1c27-4ab7-8e1a-0a4f0ca29c82",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ë‚´ë³´ë‚´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "593fa65c-2db6-47af-8fb4-131a28dd6ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: /home/j-k13s101/artifacts/char_calibrated.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib, os\n",
    "\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "joblib.dump(cal_char, \"artifacts/char_calibrated.joblib\")\n",
    "print(\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ:\", os.path.abspath(\"artifacts/char_calibrated.joblib\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
